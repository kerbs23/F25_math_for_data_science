{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fm9p3ve85y3"
   },
   "source": [
    "math 5750/6880: mathematics of data science \\\\\n",
    "project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vodhelnjxdro"
   },
   "source": [
    "# 3. python and google colab\n",
    "project euler problem  \n",
    "https://projecteuler.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_e6lm_newwd",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# pyright: basic\n",
    "# ruff: noqa: e402\n",
    "wd = \"/home/magnoliad/Desktop/F2025/math_data_sci/projects/1/Project1\"\n",
    "\n",
    "\n",
    "# conjecture: this is a prime factorization problem kinda\n",
    "# two numbers are relatively prime if their gcf == 1. so, if a # is not relatively prime to 2, then\n",
    "# it is not relatively prime to all multiples of 2.\n",
    "# similarly, if it is relatively prime to 2, and we add the condition it is relatively prime to 3, \n",
    "# it gains the multiples of 3 that are not multiples of 2 to its score.\n",
    "\n",
    "# so, each distinct prime factor helps us, and each prime that is not a factor hurts us. and, there\n",
    "# are diminishing returns to higher prime factors. this gives me an idea:\n",
    "import math as m\n",
    "from ntpath import exists\n",
    "from os import makedirs, path\n",
    "def phi(num, loud = False):\n",
    "    rel_primes = []\n",
    "    for n in range(num):\n",
    "        if m.gcd(n, num) == 1:\n",
    "            rel_primes.append(n)\n",
    "    if loud:\n",
    "        print(f\"relative primes of {num}:{rel_primes}, phi = {len(rel_primes)}\") #to test it\n",
    "    return len(rel_primes)\n",
    "\n",
    "def score(num):\n",
    "    return num/phi(num)\n",
    "\n",
    "\n",
    "print (phi(1*2*3*5, True)) #works\n",
    "print(score(1*2*3*5)) #3.75\n",
    "\n",
    "# so, the vibes tell me that the result will be the collection of primes multiplied togegher.\n",
    "# not just that, but the frequency of primes that coung against us mechanicdally shrinks as we\n",
    "# go up, so itll be the biggest of these in the range.\n",
    "\n",
    "guess = 1*2*3*5*7*11*13*17 # 19 takes us too high\n",
    "print(guess) # == 510510\n",
    "print(score(guess)) # == 5.539 ish\n",
    "\n",
    "# is my educated guess. however, i didnt write that nice score function to not then let the computer brute force it for me\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# generate scores for n in range. takes a couple mins on my labtop but its ok\n",
    "# ok fine ill admit doing this on 1 thread was not my wisest move ever. but its ok\n",
    "scores = []\n",
    "for n in range(1, 10): #set to 1000000 to see i am right\n",
    "    scores.append((n, score(n)))\n",
    "    print(\"\\r\",end=\"\")\n",
    "    print(f'checking num: {n}', end=\"\")\n",
    "\n",
    "# create dataframe and sort\n",
    "df = pd.DataFrame(scores, columns=['n', 'score'])\n",
    "df = df.sort_values('score', ascending=False)\n",
    "print(df.head)\n",
    "# shows i am right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riltqhjexnoq"
   },
   "source": [
    "# 4. regression analysis\n",
    "california housing data  \n",
    "https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5gtrmgu1kl6x"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydjnvnagkrpe",
    "outputid": "b9f703a8-5008-4b11-8dc9-a3636d7efd56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup',\n",
      "       'Latitude', 'Longitude'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# load the california housing data\n",
    "cal = fetch_california_housing(as_frame=True)\n",
    "x, y = cal.data, cal.target # pyright: ignore\n",
    "feature_names = x.columns\n",
    "print(feature_names)\n",
    "\n",
    "# train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peytefssxmk2",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import os\n",
    "\n",
    "print(x_train.columns)\n",
    "\n",
    "# i do linear regression essentially professionally, so this section will be uniquely overbuilt\n",
    "# first time using scikit-learn though so it is not totally free\n",
    "# first, from experience i want a log() of the price columns, which changes the interpretation to roughly the % change in house prices on observables\n",
    "# generally, finance crap changes as % of its total so this makes sense in that way\n",
    "\n",
    "def y_prep(y):\n",
    "    log_y = np.log(y)\n",
    "    return log_y\n",
    "\n",
    "def x_prep(x):\n",
    "    x['log_medinc'] = np.log(x['MedInc']) # my priors are basically that medinc will moetly predict the outcome\n",
    "    return x\n",
    "\n",
    "def evaluate_regression(model, x_data, y_data):\n",
    "    r2 = model.score(x_data, y_data)\n",
    "    y_pred = model.predict(x_data)\n",
    "    residuals = y_data - y_pred\n",
    "    \n",
    "    # calculate metrics\n",
    "    mse = np.mean(residuals**2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(residuals))\n",
    "    \n",
    "    # calculate coefficient standard errors\n",
    "    n = len(y_data)\n",
    "    p = x_data.shape[1]\n",
    "    mse_residual = np.sum(residuals**2) / (n - p - 1)\n",
    "    x_with_intercept = np.column_stack([np.ones(n), x_data]) if model.fit_intercept else x_train\n",
    "    cov_matrix = mse_residual * np.linalg.inv(x_with_intercept.T @ x_with_intercept)\n",
    "    std_errors = np.sqrt(np.diag(cov_matrix))\n",
    "    \n",
    "    # get coefficients (add intercept if present)\n",
    "    coefs = np.concatenate([[model.intercept_], model.coef_]) if model.fit_intercept else model.coef_\n",
    "    \n",
    "    # create result row with coefficients\n",
    "    result_data = {\n",
    "        'r2': r2,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse, \n",
    "        'mae': mae,\n",
    "        'n_samples': n,\n",
    "        'n_features': p\n",
    "    }\n",
    "    \n",
    "    # add coefficients and standard errors\n",
    "    for i, (coef, std_err) in enumerate(zip(coefs, std_errors)):\n",
    "        result_data[f'coef_{i}'] = coef\n",
    "        result_data[f'std_err_{i}'] = std_err\n",
    "    \n",
    "    return pd.DataFrame([result_data])\n",
    "\n",
    "def plot_estimate_vs_actual(model, x_data, y_true, title=\"Estimate Vs Actual\", save_path=None):\n",
    "    y_pred = model.predict(x_data)\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.scatter( y_true, y_pred, alpha=0.6, edgecolors='w', linewidth=0.5)\n",
    "    ax.axline((0, 0), slope=1, color='r', linestyle='--', alpha=0.8)\n",
    "    ax.set_xlabel('True values')\n",
    "    ax.set_ylabel('Predicted values')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi = 300)\n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_residuals_histogram(model, x_data, y_true, title=\"Residuals Distribution\", save_path=None):\n",
    "    y_pred = model.predict(x_data)\n",
    "    residuals = y_true - y_pred\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.hist(residuals, bins=30, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(x=0, color='r', linestyle='--', alpha=0.8)\n",
    "    ax.set_xlabel('Residuals')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "x_train_processed = x_prep(x_train)\n",
    "y_train_processed = y_prep(y_train)\n",
    "\n",
    "# first, lets look at each varible one by one without prep\n",
    "results = []\n",
    "\n",
    "for feature in x_train_processed.columns:\n",
    "    # Fit simple linear regression for each feature\n",
    "    X_single = x_train_processed[[feature]]  # Keep as DataFrame for feature name\n",
    "    model = LinearRegression().fit(X_single, y_train_processed)\n",
    "    evaluation = evaluate_regression(model, X_single, y_train_processed)\n",
    "    evaluation['feature'] = feature\n",
    "    results.append(evaluation)\n",
    "\n",
    "results = pd.concat(results, axis=0, ignore_index=True)\n",
    "\n",
    "print(results)\n",
    "results.to_csv('coeffs.csv')\n",
    "\n",
    "# Checking it out in dv, by far the highest r2 is for log_medinc, followed by ave_rooms\n",
    "# It only looks like the population is clearly insignificant, although the ave bedrms and ave occp do not inspire confidence\n",
    "# Interestingly, the log-log on the medinc has a slightly lower r2, but I think Ill leave it as is.\n",
    "# also, I think the lat-long are misspecified. splitting them up into 2 interacted categoricals would probably help,\n",
    "# but also be a lot of work and not the point of this assign.\n",
    "\n",
    "# So next I think I will use all of the regressors except population, and see if anything looses its significance\n",
    "\n",
    "plots_dir = f'{wd}/plots/'\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "x_spec_2 = x_train_processed[['HouseAge', 'AveRooms', 'AveBedrms', 'AveOccup', 'Latitude', 'Longitude', 'log_medinc']]\n",
    "model = LinearRegression().fit(x_spec_2, y_train_processed)\n",
    "evaluation = evaluate_regression(model, x_spec_2, y_train_processed)\n",
    "print(evaluation)\n",
    "evaluation.to_csv('coeffs2.csv')\n",
    "error_chart = plot_estimate_vs_actual(model, x_spec_2, y_train_processed, title=\"Spec 2 pred v actual comparison\", save_path=f'{plots_dir}Spec_2_pred_v_actual')\n",
    "residual_histogram = plot_residuals_histogram(model, x_spec_2, y_train_processed, title=\"Spec 2 residual histogram\", save_path=f'{plots_dir}Spec_2_residual_hist')\n",
    "# Happy with that, now to validate with the test data\n",
    "\n",
    "x_test_processed = x_prep(x_test)\n",
    "y_test_processed = y_prep(y_test)\n",
    "x_spec_2_test = x_test_processed[['HouseAge', 'AveRooms', 'AveBedrms', 'AveOccup', 'Latitude', 'Longitude', 'log_medinc']]\n",
    "evaluation = evaluate_regression(model, x_spec_2_test, y_test_processed)\n",
    "print(evaluation)\n",
    "evaluation.to_csv('coeffs2.csv')\n",
    "error_chart = plot_estimate_vs_actual(model, x_spec_2_test, y_test_processed, title=\"Spec 2 pred v actual comparison (test data)\", save_path=f'{plots_dir}Spec_2_pred_v_actual_test')\n",
    "residual_histogram = plot_residuals_histogram(model, x_spec_2_test, y_test_processed, title=\"Spec 2 residual histogram (test data)\", save_path=f'{plots_dir}Spec_2_residual_hist_test')\n",
    "\n",
    "\n",
    "# Ill use ridge regression? I really dont get any of these things and this seems to  be the most comprehensible.\n",
    "\n",
    "x_spec_2 = x_train_processed[['HouseAge', 'AveRooms', 'AveBedrms', 'AveOccup', 'Latitude', 'Longitude', 'log_medinc']]\n",
    "model = Ridge().fit(x_spec_2, y_train_processed)\n",
    "evaluation = evaluate_regression(model, x_spec_2, y_train_processed)\n",
    "print(evaluation)\n",
    "evaluation.to_csv('coeffs2.csv')\n",
    "error_chart = plot_estimate_vs_actual(model, x_spec_2, y_train_processed, title=\"Spec 2 pred v actual comparison\", save_path=f'{plots_dir}Spec_2_pred_v_actual')\n",
    "residual_histogram = plot_residuals_histogram(model, x_spec_2, y_train_processed, title=\"Spec 2 residual histogram\", save_path=f'{plots_dir}Spec_2_residual_hist')\n",
    "# Happy with that, now to validate with the test data\n",
    "\n",
    "x_test_processed = x_prep(x_test)\n",
    "y_test_processed = y_prep(y_test)\n",
    "x_spec_2_test = x_test_processed[['HouseAge', 'AveRooms', 'AveBedrms', 'AveOccup', 'Latitude', 'Longitude', 'log_medinc']]\n",
    "evaluation = evaluate_regression(model, x_spec_2_test, y_test_processed)\n",
    "print(evaluation)\n",
    "evaluation.to_csv('coeffs2.csv')\n",
    "error_chart = plot_estimate_vs_actual(model, x_spec_2_test, y_test_processed, title=\"Spec 2 pred v actual comparison (test data)\", save_path=f'{plots_dir}Spec_2_pred_v_actual_test')\n",
    "residual_histogram = plot_residuals_histogram(model, x_spec_2_test, y_test_processed, title=\"Spec 2 residual histogram (test data)\", save_path=f'{plots_dir}Spec_2_residual_hist_test')\n",
    "\n",
    "# Well, no difference. I think that makes sense because there isnt a lot of colinearity here, which is what it says\n",
    "# the ridge regression is better for.\n",
    "\n",
    "# on to the next thing I suppose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkSVMB7HXSZB"
   },
   "source": [
    "# 5. Classification Analysis\n",
    "Diagnostic Wisconsin Breast Cancer Database  \n",
    "https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vUfQhEk7zQBX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IGeihULRzZxD",
    "outputId": "b7cff0d4-9149-4208-c92c-6fedb809d25b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
      "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
      "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
      "       'worst concave points', 'worst symmetry', 'worst fractal dimension'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load Breast Cancer Wisconsin Dataset\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target                  # 0 = malignant, 1 = benign\n",
    "feature_names = X.columns\n",
    "label_names = {0: \"malignant\", 1: \"benign\"}\n",
    "print(feature_names)\n",
    "\n",
    "# Train/Test Split (stratified to preserve class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0, stratify=y)\n",
    "\n",
    "# Preprocess Data (fit on train ONLY; then transform both)\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_std = scaler.fit_transform(X_train)   # fit on train\n",
    "X_test_std  = scaler.transform(X_test)        # transform test with train stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QUYeDq2ZXY2x",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score, confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "print(X_train_std)\n",
    "print(y_train)\n",
    "\n",
    "# well ok similar situation. \n",
    "\n",
    "def evaluate_model_performance(model, X, y_true, set_name=\"\"):\n",
    "    y_pred = model.predict(X)\n",
    "    y_score = model.predict_proba(X)[:, 1]  # Gets probability for the positive class\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "    avg_precision = average_precision_score(y_true, y_score)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n--- {set_name} Set Performance ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "    \n",
    "    return {'accuracy': accuracy, 'roc_auc': roc_auc, 'avg_precision': avg_precision}\n",
    "\n",
    "def generate_model_plots(model, X, y_true, set_name=\"\", save_path=None):\n",
    "    \"\"\"\n",
    "    Generates and displays a confusion matrix, ROC curve, and Precision-Recall curve.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    y_score = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.suptitle(f'{set_name} Set Diagnostics', fontweight='bold')\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    ax1.matshow(cm, cmap='Blues', alpha=0.7)\n",
    "    ax1.set_title('Confusion Matrix')\n",
    "    for (i, j), val in np.ndenumerate(cm):\n",
    "        ax1.text(j, i, f'{val}', ha='center', va='center')\n",
    "    \n",
    "    # ROC Curve\n",
    "    RocCurveDisplay.from_estimator(model, X, y_true, ax=ax2)\n",
    "    ax2.set_title('ROC Curve')\n",
    "    ax2.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random classifier\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    PrecisionRecallDisplay.from_estimator(model, X, y_true, ax=ax3)\n",
    "    ax3.set_title('Precision-Recall Curve')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi = 300)\n",
    "    plt.show()\n",
    "\n",
    "model = SVC(probability=True, random_state=42)\n",
    "\n",
    "model.fit(X_train_std, y_train)\n",
    "\n",
    "# Use the above functs to evaluate the Performance on the training data:\n",
    "evaluate_model_performance(model, X_train_std, y_train, \"SVC Training Performance Eval\")\n",
    "generate_model_plots(model, X_train_std, y_train, \"SVC Training Performance Eval\", save_path=f'{plots_dir}SVC_training_eval')\n",
    "\n",
    "# and now the test data:\n",
    "evaluate_model_performance(model, X_test_std, y_test, \"SVC Test Performance Eval\")\n",
    "generate_model_plots(model, X_test_std, y_test, \"SVC Test Performance Eval\", save_path=f'{plots_dir}SVC_test_eval')\n",
    "# takes a bit of a hit but well within things still being fine\n",
    "# Now onto another method. Used KNN, seems interesting and I think I kinda get it.\n",
    "# Though im not sure it is strictly classification but.\n",
    "results = []\n",
    "for n in range(2, 20, 2):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=n)\n",
    "    knn_model.fit(X_train_std, y_train)\n",
    "    evaluation = evaluate_model_performance(knn_model, X_test_std, y_test)\n",
    "    evaluation['n_neighbors'] = n\n",
    "    results.append(evaluation)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"knn_comparisons.csv\")\n",
    "# Looks best at 8, so\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=8)\n",
    "knn_model.fit(X_train_std, y_train)\n",
    "evaluate_model_performance(knn_model, X_test_std, y_test, \"knn Test Performance Eval\")\n",
    "generate_model_plots(knn_model, X_test_std, y_test, \"knn Test Performance Eval\", save_path=f'{plots_dir}knn_training_eval')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
